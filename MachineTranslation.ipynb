{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oKwlcfHfTVr7"
      },
      "outputs": [],
      "source": [
        "# !pip install torchtext==0.9.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qs9S29KcXsjU",
        "outputId": "1372a21c-17c0-482a-ce1d-9c0ac258a9bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aJTj_87kMZ_C"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import time\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import random\n",
        "# from utils import translate_sentence, bleu, save_checkpoint, load_checkpoint\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from torchtext.legacy.datasets import Multi30k\n",
        "from torchtext.legacy.data import Field, BucketIterator\n",
        "import spacy\n",
        "import numpy as np\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "from torchtext.data.metrics import bleu_score\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B4IeBMeme9CU",
        "outputId": "6be617f8-d3ef-4648-e42c-6a0e0b8e0c15"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting en_core_web_sm==2.2.5\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz (12.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 12.0 MB 2.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.7/dist-packages (from en_core_web_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.9.1)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (4.64.0)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (57.4.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.21.6)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.6)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.6)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.6)\n",
            "Requirement already satisfied: importlib-metadata>=0.20 in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (4.11.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.8.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (4.1.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.24.3)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/en_core_web_sm -->\n",
            "/usr/local/lib/python3.7/dist-packages/spacy/data/en\n",
            "You can now load the model via spacy.load('en')\n",
            "Collecting de_core_news_sm==2.2.5\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/de_core_news_sm-2.2.5/de_core_news_sm-2.2.5.tar.gz (14.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 14.9 MB 5.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.7/dist-packages (from de_core_news_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (2.0.6)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (0.9.1)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (57.4.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.0.6)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (3.0.6)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (4.64.0)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.21.6)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: importlib-metadata>=0.20 in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->de_core_news_sm==2.2.5) (4.11.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->de_core_news_sm==2.2.5) (3.8.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->de_core_news_sm==2.2.5) (4.1.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (2.10)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('de_core_news_sm')\n",
            "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/de_core_news_sm -->\n",
            "/usr/local/lib/python3.7/dist-packages/spacy/data/de\n",
            "You can now load the model via spacy.load('de')\n"
          ]
        }
      ],
      "source": [
        "# Tutorial link: https://www.youtube.com/watch?v=EoGUlvhRYpk&list=RDCMUCkzW5JSFwvKRjXABI-UTAkQ\n",
        "\n",
        "\n",
        "#Download languade package from spacy\n",
        "!python -m spacy download en\n",
        "!python -m spacy download de\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kNB6eT2TKPnI"
      },
      "outputs": [],
      "source": [
        "# from torchtext.data import Field, BucketIterator\n",
        "\n",
        "spacy_ger = spacy.load(\"de\")\n",
        "spacy_eng = spacy.load(\"en\")\n",
        "\n",
        "\n",
        "def tokenize_ger(text):\n",
        "    return [tok.text for tok in spacy_ger.tokenizer(text)]\n",
        "# .text converts object into string.\n",
        "\n",
        "def tokenize_eng(text):\n",
        "    return [tok.text for tok in spacy_eng.tokenizer(text)]\n",
        "\n",
        "\n",
        "# Field class models common text processing datatypes that can be represented by tensors.\n",
        "german = Field(tokenize=tokenize_ger, lower=True, init_token=\"<sos>\", eos_token=\"<eos>\")\n",
        "\n",
        "english = Field(tokenize=tokenize_eng, lower=True, init_token=\"<sos>\", eos_token=\"<eos>\")\n",
        "\n",
        "train_data, valid_data, test_data = Multi30k.splits(\n",
        "    exts=(\".de\", \".en\"), fields=(german, english)\n",
        ")\n",
        "\n",
        "\n",
        "# Creating a vocab object for both language using build_vocab\n",
        "german.build_vocab(train_data, max_size=10000, min_freq=2)\n",
        "english.build_vocab(train_data, max_size=10000, min_freq=2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p32w8JyIU2sw"
      },
      "outputs": [],
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_size, embedding_size, hidden_size, num_layers, p):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.dropout = nn.Dropout(p)\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        self.embedding = nn.Embedding(input_size, embedding_size)\n",
        "        self.rnn = nn.LSTM(embedding_size, hidden_size, num_layers, dropout=p)\n",
        "\n",
        "    def forward(self,x):\n",
        "        # x-shape = (seq_length,N) [N is batch size]\n",
        "\n",
        "        embedding = self.dropout(self.embedding(x))\n",
        "        # embedding-shape = (seq_length,N,embedding_size)\n",
        "\n",
        "        outputs,(hidden,cell) = self.rnn(embedding)\n",
        "\n",
        "        return hidden, cell\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YcY_mKDJfCpW"
      },
      "outputs": [],
      "source": [
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(\n",
        "        self, input_size, embedding_size, hidden_size, output_size, num_layers, p\n",
        "    ):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.dropout = nn.Dropout(p)\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        self.embedding = nn.Embedding(input_size, embedding_size)\n",
        "        self.rnn = nn.LSTM(embedding_size, hidden_size, num_layers, dropout=p)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x, hidden, cell):\n",
        "        # x shape: (N) where N is for batch size, we want it to be (1, N), seq_length\n",
        "        # is 1 here because we are sending in a single word and not a sentence\n",
        "        x = x.unsqueeze(0)\n",
        "\n",
        "        \n",
        "        embedding = self.dropout(self.embedding(x))\n",
        "        # embedding-shape = (1,N,embedding_size)\n",
        "\n",
        "        outputs,(hidden,cell) = self.rnn(embedding,(hidden,cell))\n",
        "        # shape of output: (1, N ,hidden_size)\n",
        "\n",
        "        prediction = self.fc(outputs)\n",
        "        # output_size: size of output vocab language\n",
        "        # shape: (1,N,output_size)\n",
        "        # we need (N,output_size)\n",
        "        prediction = prediction.squeeze(0)\n",
        "\n",
        "        return prediction, hidden,cell\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yMlk71w0fDcW"
      },
      "outputs": [],
      "source": [
        "class Seq2Seq(nn.Module):\n",
        "  def __init__(self,encoder, decoder):\n",
        "    super(Seq2Seq,self).__init__()\n",
        "    self.encoder = encoder\n",
        "    self.decoder = decoder\n",
        "\n",
        "  def forward(self,source,target,teacher_force_ratio=0.5):\n",
        "\n",
        "    # Source: betch of input sentence (sentence_len,batch_size)\n",
        "    batch_size = source.shape[1]\n",
        "    target_len = target.shape[0]\n",
        "    target_vocab_size = len(english.vocab)\n",
        "\n",
        "    hidden ,cell = self.encoder(source)\n",
        "\n",
        "    outputs = torch.zeros(target_len,batch_size,target_vocab_size).to(device)\n",
        "    # grab start token\n",
        "    x = target[0]\n",
        "\n",
        "    for i in range(1,target_len):\n",
        "      output, hidden ,cell = self.decoder(x,hidden,cell)\n",
        "\n",
        "      #(N,output vocab_size)\n",
        "      outputs[i] = output\n",
        "\n",
        "      # chooses between original output word and predicted output with probability of teacher_force_ratio\n",
        "      best_guess = output.argmax(1)\n",
        "      x = target[i] if random.random() < teacher_force_ratio else best_guess\n",
        "    \n",
        "    return outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a1o67VrlAfbk"
      },
      "outputs": [],
      "source": [
        "input_size_encoder = len(german.vocab)\n",
        "input_size_decoder = len(english.vocab)\n",
        "output_size = len(english.vocab)\n",
        "encoder_embedding_size = 300\n",
        "decoder_embedding_size = 300\n",
        "hidden_size = 1024\n",
        "n_layers = 2\n",
        "enc_dropout = 0.5\n",
        "dec_dropout = 0.5\n",
        "batch_size = 64\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "giHGksWSWl-g"
      },
      "outputs": [],
      "source": [
        "train_iterator, valid_iterator, test_iterator = BucketIterator.splits(\n",
        "    (train_data, valid_data, test_data),\n",
        "    batch_size=batch_size,\n",
        "    sort_within_batch=True,\n",
        "    sort_key=lambda x: len(x.src),\n",
        "    device=device,\n",
        ")\n",
        "\n",
        "# This automatically adds padding\n",
        "# x.src is input and x.trg is output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q0666_5i_3ps"
      },
      "outputs": [],
      "source": [
        "encoder_net = Encoder(input_size_encoder,encoder_embedding_size,hidden_size,n_layers,enc_dropout).to(device)\n",
        "\n",
        "decoder_net = Decoder(input_size_decoder,decoder_embedding_size,hidden_size,output_size,n_layers,dec_dropout).to(device)\n",
        "\n",
        "model = Seq2Seq(encoder_net,decoder_net).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VD4XdzEIEpDD"
      },
      "outputs": [],
      "source": [
        "# get index of <PAD> from vocabulary\n",
        "pad_idx = english.vocab.stoi[\"<pad>\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LBClDtcjHtRu"
      },
      "outputs": [],
      "source": [
        "num_epochs = 100\n",
        "learning_rate = 0.0001\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(ignore_index = pad_idx)\n",
        "optimizer = optim.Adam(model.parameters(),lr = learning_rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bIYw4wM6XYfX"
      },
      "outputs": [],
      "source": [
        "# Tensorboard to get nice loss plot\n",
        "writer = SummaryWriter(f\"runs/loss_plot\")\n",
        "step = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ayt-PqAurdjr"
      },
      "outputs": [],
      "source": [
        "# Loss variables\n",
        "losses = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y-KWTkHEF9cA",
        "outputId": "49f1717b-0515-458d-ba72-a88a9cc1540c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 111 in total 150 Epochs Training-loss:0.01803998090326786 Time taken: 58.29538655281067\n",
            "Epoch 112 in total 150 Epochs Training-loss:0.015289335511624813 Time taken: 59.751731395721436\n",
            "Epoch 113 in total 150 Epochs Training-loss:0.016247805207967758 Time taken: 60.308337688446045\n",
            "Epoch 114 in total 150 Epochs Training-loss:0.026776328682899475 Time taken: 60.20340156555176\n",
            "Epoch 115 in total 150 Epochs Training-loss:0.04024677723646164 Time taken: 60.347891330718994\n",
            "Epoch 116 in total 150 Epochs Training-loss:0.06525977700948715 Time taken: 60.36409616470337\n",
            "Epoch 117 in total 150 Epochs Training-loss:0.0648874044418335 Time taken: 60.49260473251343\n",
            "Epoch 118 in total 150 Epochs Training-loss:0.03940778970718384 Time taken: 60.34889221191406\n",
            "Epoch 119 in total 150 Epochs Training-loss:0.02775331400334835 Time taken: 60.29300594329834\n",
            "Epoch 120 in total 150 Epochs Training-loss:0.058879490941762924 Time taken: 60.79063105583191\n",
            "Epoch 121 in total 150 Epochs Training-loss:0.06393774598836899 Time taken: 60.33489632606506\n",
            "Epoch 122 in total 150 Epochs Training-loss:0.030376605689525604 Time taken: 60.29693341255188\n",
            "Epoch 123 in total 150 Epochs Training-loss:0.03029274195432663 Time taken: 60.30687618255615\n",
            "Epoch 124 in total 150 Epochs Training-loss:0.024139029905200005 Time taken: 60.31777501106262\n",
            "Epoch 125 in total 150 Epochs Training-loss:0.02930532582104206 Time taken: 60.273805379867554\n",
            "Epoch 126 in total 150 Epochs Training-loss:0.03030707687139511 Time taken: 60.28598475456238\n",
            "Epoch 127 in total 150 Epochs Training-loss:0.024082090705633163 Time taken: 60.42402267456055\n",
            "Epoch 128 in total 150 Epochs Training-loss:0.009850874543190002 Time taken: 60.26757621765137\n",
            "Epoch 129 in total 150 Epochs Training-loss:0.0699329748749733 Time taken: 60.37054419517517\n",
            "Epoch 130 in total 150 Epochs Training-loss:0.018466755747795105 Time taken: 60.79112362861633\n",
            "Epoch 131 in total 150 Epochs Training-loss:0.056945767253637314 Time taken: 60.65355110168457\n",
            "Epoch 132 in total 150 Epochs Training-loss:0.01960882917046547 Time taken: 60.884265422821045\n",
            "Epoch 133 in total 150 Epochs Training-loss:0.025213629007339478 Time taken: 60.28040552139282\n",
            "Epoch 134 in total 150 Epochs Training-loss:0.016094330698251724 Time taken: 60.604904890060425\n",
            "Epoch 135 in total 150 Epochs Training-loss:0.026894163340330124 Time taken: 60.5472297668457\n",
            "Epoch 136 in total 150 Epochs Training-loss:0.032280102372169495 Time taken: 60.33336424827576\n",
            "Epoch 137 in total 150 Epochs Training-loss:0.018825678154826164 Time taken: 61.155802965164185\n",
            "Epoch 138 in total 150 Epochs Training-loss:0.021802103146910667 Time taken: 60.53077006340027\n",
            "Epoch 139 in total 150 Epochs Training-loss:0.023982901126146317 Time taken: 60.725446462631226\n",
            "Epoch 140 in total 150 Epochs Training-loss:0.016008922830224037 Time taken: 61.29781150817871\n",
            "Epoch 141 in total 150 Epochs Training-loss:0.02969171106815338 Time taken: 60.30378842353821\n",
            "Epoch 142 in total 150 Epochs Training-loss:0.08071297407150269 Time taken: 60.32318949699402\n",
            "Epoch 143 in total 150 Epochs Training-loss:0.09477106481790543 Time taken: 60.24702334403992\n",
            "Epoch 144 in total 150 Epochs Training-loss:0.018941937014460564 Time taken: 60.11394262313843\n",
            "Epoch 145 in total 150 Epochs Training-loss:0.025788314640522003 Time taken: 60.31289267539978\n",
            "Epoch 146 in total 150 Epochs Training-loss:0.07569098472595215 Time taken: 60.23712491989136\n",
            "Epoch 147 in total 150 Epochs Training-loss:0.12387116998434067 Time taken: 60.38385224342346\n",
            "Epoch 148 in total 150 Epochs Training-loss:0.04010676592588425 Time taken: 60.265207052230835\n",
            "Epoch 149 in total 150 Epochs Training-loss:0.025743840262293816 Time taken: 60.31325840950012\n"
          ]
        }
      ],
      "source": [
        "## Training the model\n",
        "\n",
        "for epoch in range(111,num_epochs+50):\n",
        "  \n",
        "  epoch_loss = 0\n",
        "  timenow = time.time()\n",
        "  model.train()\n",
        "  for batch_index, batch in enumerate(train_iterator):\n",
        "    input = batch.src.to(device)\n",
        "    target = batch.trg.to(device)\n",
        "\n",
        "    output = model(input,target)\n",
        "    # output shape = (target_len,batch_size,output_vocab_len)\n",
        "\n",
        "\n",
        "    output = output[1:].reshape(-1,output.shape[2])\n",
        "    target = target[1:].reshape(-1)\n",
        "    # [1:] because we won't be taking start token <SOS>\n",
        "    # reshape because loss function does not allow this shape\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss = criterion(output,target)\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    # to avoid eploding gradient problems\n",
        "    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
        "\n",
        "    optimizer.step()\n",
        "    \n",
        "    \n",
        "    writer.add_scalar(\"Training loss\", loss, global_step=step)\n",
        "    step += 1\n",
        "    epoch_loss = loss\n",
        "    \n",
        "  losses.append(epoch_loss)\n",
        "  if epoch%10 == 0:\n",
        "    torch.save(model.state_dict(), f'/content/drive/MyDrive/ChatBot/MTCheckpoint{epoch}.pth')\n",
        "\n",
        "  print(f'Epoch {epoch} in total {num_epochs+50} Epochs Training-loss:{epoch_loss} Time taken: {time.time() - timenow}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c36uNVh5zQJn",
        "outputId": "382110b5-b417-4862-99d9-c8603a2c5505"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ],
      "source": [
        "model = Seq2Seq(encoder_net,decoder_net).to(device)\n",
        "model.load_state_dict(torch.load('/content/drive/MyDrive/ChatBot/MTCheckpoint140.pth'))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def bleu(data, model, german, english, device):\n",
        "    targets = []\n",
        "    outputs = []\n",
        "\n",
        "    for example in data:\n",
        "        src = vars(example)[\"src\"]\n",
        "        trg = vars(example)[\"trg\"]\n",
        "\n",
        "        prediction = translate_sentence(model, src, german, english, device)\n",
        "        prediction = prediction[:-1]  # remove <eos> token\n",
        "\n",
        "        targets.append([trg])\n",
        "        outputs.append(prediction)\n",
        "\n",
        "    return bleu_score(outputs, targets)\n",
        "\n",
        "score = bleu(test_data[1:100], model, german, english, device)\n",
        "print(f\"Bleu score {score*100:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_OZAkeROLr1_",
        "outputId": "a6e51451-5152-4a62-caaa-6d73e07074be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bleu score 18.98\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def translate_sentence(model, sentence, german, english, device, max_length=50):\n",
        "\n",
        "\n",
        "    # Create tokens using spacy and everything in lower case (which is what our vocab is)\n",
        "    if type(sentence) == str:\n",
        "        tokens = [token.text.lower() for token in spacy_ger(sentence)]\n",
        "    else:\n",
        "        tokens = [token.lower() for token in sentence]\n",
        "\n",
        "    # print(tokens)\n",
        "\n",
        "    # Add <SOS> and <EOS> in beginning and end respectively\n",
        "    tokens.insert(0, german.init_token)\n",
        "    tokens.append(german.eos_token)\n",
        "\n",
        "    # Go through each german token and convert to an index\n",
        "    text_to_indices = [german.vocab.stoi[token] for token in tokens]\n",
        "\n",
        "    # Convert to Tensor\n",
        "    sentence_tensor = torch.LongTensor(text_to_indices).unsqueeze(1).to(device)\n",
        "\n",
        "    # Build encoder hidden, cell state\n",
        "    with torch.no_grad():\n",
        "        hidden, cell = model.encoder(sentence_tensor)\n",
        "\n",
        "    outputs = [english.vocab.stoi[\"<sos>\"]]\n",
        "\n",
        "    for _ in range(max_length):\n",
        "        previous_word = torch.LongTensor([outputs[-1]]).to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            output, hidden, cell = model.decoder(previous_word, hidden, cell)\n",
        "            best_guess = output.argmax(1).item()\n",
        "\n",
        "        outputs.append(best_guess)\n",
        "\n",
        "        # Model predicts it's the end of the sentence\n",
        "        if output.argmax(1).item() == english.vocab.stoi[\"<eos>\"]:\n",
        "            break\n",
        "\n",
        "    translated_sentence = [english.vocab.itos[idx] for idx in outputs]\n",
        "\n",
        "    # remove start token\n",
        "    return translated_sentence[1:]\n"
      ],
      "metadata": {
        "id": "nXdak9myACGJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = \"Hier sind einige erstaunliche Ideen für Essays und Reden, die Sie beim Schreiben eines perfekten Essays und perfekter Reden für den Wettbewerb unterstützen werden.\"\n",
        "\n",
        "translated = translate_sentence(\n",
        "        model, sentence, german, english, device, max_length=50\n",
        "    )\n",
        "\n",
        "print(translated)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pj6r9fJCBZMO",
        "outputId": "ee3ddf01-fed0-4407-8bc4-5516c0915fbe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['there', '<unk>', '<unk>', '<unk>', '<unk>', 'keeping', 'peace', 'and', 'and', 'a', 'going', '-', 'camera', 'the', 'is', 'a', 'for', 'the', '<unk>', 'for', 'the', 'picture', '.', '<eos>']\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "MachineTranslation.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}